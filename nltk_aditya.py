import nltk
from nltk import RegexpParser
from nltk.tree import Tree
from nltk.tokenize import TreebankWordTokenizer

# ğŸ”½ Download required NLTK models for POS tagging
nltk.download('averaged_perceptron_tagger')  # For tagging words with POS tags

# âœ… Use Treebank tokenizer (instead of default sent_tokenize) to avoid punkt_tab error
tokenizer = TreebankWordTokenizer()

# ğŸ“ Sample text
text = "Alice in Wonderland."

# ğŸ”¹ Tokenize the sentence into words
tokens = tokenizer.tokenize(text)
print(f"Tokens: {tokens}")  # ['Alice', 'in', 'Wonderland', '.']

# ğŸ”¹ Apply POS (Part-of-Speech) tagging
tags = nltk.pos_tag(tokens)
print(f"POS Tags: {tags}")
# Output: [('Alice', 'NNP'), ('in', 'IN'), ('Wonderland', 'NNP'), ('.', '.')]

# ğŸ”¹ Define chunking rule using regular expressions
# NP = Noun Phrase â†’ Chunk together one or more proper nouns (NNP)
grammar = r"""
    NP: {<NNP>+}  # One or more Proper Nouns (e.g., 'Alice Wonderland')
"""

# ğŸ”¹ Create a chunk parser with the rule above
chunker = RegexpParser(grammar)

# ğŸ”¹ Apply chunking on POS-tagged sentence
tree = chunker.parse(tags)

# ğŸŒ³ Print the chunked tree as text
print("\nChunked Tree:")
print(tree)

# ğŸŒ³ Pretty print tree in terminal
tree.pretty_print()  # Visual tree structure
